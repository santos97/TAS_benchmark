Executed a Technical AI Safety (TAS) benchmark for a 4-bit quantized Small Language Model (Phi-2) on a resource-constrained Google Colab environment. Leveraged open-source adversarial datasets (WildJailbreak) to test Safeguard Robustness against sophisticated jailbreak attacks. Quantified the direct impact of optimization, demonstrating a disproportionate decline in the modelâ€™s ability to resist complex adversarial inputs.
